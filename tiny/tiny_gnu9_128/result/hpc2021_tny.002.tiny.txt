############################################################################################################
#   INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN                                #
#                                                                                                          #
# Your run was marked invalid because it has one or more flags in the                                      #
# "unknown" category. You might be able to resolve this problem without                                    #
# re-running your test; see                                                                                #
#      https://www.spec.org/hpc2021/Docs/runhpc.html#flagsurl                                              #
# for more information.                                                                                    #
#                                                                                                          #
#   INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN                                #
############################################################################################################
                                        SPEChpc(TM) 2021 Tiny Result
                                        Mega Technology Big Compute
                                    Test Sponsor: University of Bristol

                hpc2021 License: ?                                       Test date: Aug-2022
                Test sponsor: University of Bristol          Hardware availability: Nov-2099
                Tested by:    University of Bristol          Software availability: Nov-2099

                       Estimated                       Estimated
               Base   Base    Thrds   Base       Base         Peak   Peak   Thrds    Peak       Peak
Benchmarks     Model  Ranks  pr Rnk   Run Time   Ratio        Model  Ranks  pr Rnk   Run Time   Ratio
-------------- ------ ------  ------  ---------  ---------    ------ ------  ------  ---------  ---------   
505.lbm_t         MPI    128       1        221      10.2   S                                                
505.lbm_t         MPI    128       1        221      10.2   *                                                
513.soma_t        MPI    128       1        451       8.20  S                                                
513.soma_t        MPI    128       1        455       8.14  *                                                
518.tealeaf_t     MPI    128       1       1489       1.11  *                                                
518.tealeaf_t     MPI    128       1       1101       1.50  S                                                
519.clvleaf_t     MPI    128       1        300       5.51  S                                                
519.clvleaf_t     MPI    128       1        306       5.39  *                                                
521.miniswp_t     MPI    128       1        255       6.28  S                                                
521.miniswp_t     MPI    128       1        264       6.06  *                                                
528.pot3d_t       MPI    128       1        581       3.66  S                                                
528.pot3d_t       MPI    128       1        688       3.09  *                                                
532.sph_exa_t     MPI    128       1        304       6.42  S                                                
532.sph_exa_t     MPI    128       1        327       5.97  *                                                
534.hpgmgfv_t     MPI    128       1        276       4.26  S                                                
534.hpgmgfv_t     MPI    128       1        283       4.16  *                                                
535.weather_t     MPI    128       1        363       8.88  S                                                
535.weather_t     MPI    128       1        368       8.77  *                                                
============================================================================================================
505.lbm_t         MPI    128       1        221      10.2   *                                                
513.soma_t        MPI    128       1        455       8.14  *                                                
518.tealeaf_t     MPI    128       1       1489       1.11  *                                                
519.clvleaf_t     MPI    128       1        306       5.39  *                                                
521.miniswp_t     MPI    128       1        264       6.06  *                                                
528.pot3d_t       MPI    128       1        688       3.09  *                                                
532.sph_exa_t     MPI    128       1        327       5.97  *                                                
534.hpgmgfv_t     MPI    128       1        283       4.16  *                                                
535.weather_t     MPI    128       1        368       8.77  *                                                
 Est. SPEChpc 2021_tny_base                           5.02
 Est. SPEChpc 2021_tny_peak                                                                       Not Run


                                             BENCHMARK DETAILS
                                             -----------------
      Type of System: Homogenous Cluster
  Compute Nodes Used: 8
         Total Chips: 8
         Total Cores: 512
       Total Threads: 512
        Total Memory: 2 TB
            Compiler: C/C++/Fortran: GCC Version 7.3.1
         MPI Library: OpenMPI Version 4.1.1
 Base Parallel Model: MPI
      Base Ranks Run: 128
    Base Threads Run: 1
Peak Parallel Models: Not Run

                                    Node Description: TurboBlaster 5000
                                    ===================================


                                                  HARDWARE
                                                  --------
     Number of nodes: 8
    Uses of the node: compute
              Vendor: Mega Technology
               Model: Turblaster 5000
            CPU Name: Turbo CPU
    CPU(s) orderable: 1 chips
       Chips enabled: 1
       Cores enabled: 64
      Cores per chip: 64
    Threads per core: 1
 CPU Characteristics: Turbo up to 3.4 GHz
             CPU MHz: 2250
       Primary Cache: 32 KB I + 32 KB D on chip per core
     Secondary Cache: 512 KB I+D on chip per core
            L3 Cache: 256 MB I+D on chip per chip
                      16 MB shared / 4 cores
         Other Cache: None
              Memory: 256 GB (8 x 32 GB 2Rx8 PC4-3200AA-R)
      Disk Subsystem: 1 x 480 GB  SATA 2.5" SSD
      Other Hardware: None
         Accel Count: 4
         Accel Model: Tesla V100-PCIE-16GB
        Accel Vendor: NVIDIA Corporation
          Accel Type: GPU
    Accel Connection: PCIe 3.0 16x
   Accel ECC enabled: Yes
   Accel Description: See Notes
             Adapter: None
  Number of Adapters: 0
           Slot Type: None
           Data Rate: None
          Ports Used: 0
   Interconnect Type: None


                                                  SOFTWARE
                                                  --------
             Adapter: None
      Adapter Driver: None
    Adapter Firmware: None
    Operating System: Amazon Linux 2
                      Linux 5.10.112-108.499.amzn2.aarch64
   Local File System: xfs
  Shared File System: None
        System State: Multi-user, run level 3
      Other Software: None


                                           Node Description: NFS
                                           =====================


                                                  HARDWARE
                                                  --------
     Number of nodes: 1
    Uses of the node: Fileserver
              Vendor: Big Storage Company
               Model: BG650
            CPU Name: Intel Xeon Platinum 8280
    CPU(s) orderable: 1-2 chips
       Chips enabled: 2
       Cores enabled: 56
      Cores per chip: 28
    Threads per core: 1
 CPU Characteristics: None
             CPU MHz: 2700
       Primary Cache: 32 KB I + 32 KB D on chip per core
     Secondary Cache: 1 MB I+D on chip per core
            L3 Cache: 39424 KB I+D on chip per chip
         Other Cache: None
              Memory: 768 GB (24 x 32 GB 2Rx4 PC4-2933Y-R)
      Disk Subsystem: 1 x 1 TB 12 Gbps SAS 2.5" SSD (JBOD)
      Other Hardware: None
  Number of Adapters: 1
           Slot Type: PCI-Express 3.0 x16
           Data Rate: 100 Gb/s
          Ports Used: 1
   Interconnect Type: BG 5000 series


                                                  SOFTWARE
                                                  --------
      Adapter Driver: 10.9.1.0.15
    Adapter Firmware: 10.9.0.1.0
    Operating System: Red Hat Enterprise Linux Server release 7.6
   Local File System: None
  Shared File System: NFS
        System State: Multi-User, run level 3
      Other Software: None


                             Interconnect Description: Big Interconnect Company
                             ==================================================


                                                  HARDWARE
                                                  --------
              Vendor: Big Interconnect Company
               Model: BI 100 Series
        Switch Model: BI 100 Series 48 Port 2
                      PSU
  Number of Switches: 1
     Number of Ports: 48
           Data Rate: 100 Gb/s
            Firmware: 10.3.0.0.60
            Topology: Mesh
         Primary Use: MPI Traffic


                                                  SOFTWARE
                                                  --------



                                                Submit Notes
                                                ------------
    The config file option 'submit' was used.

                                           Compiler Version Notes
                                           ----------------------
    ==============================================================================
     FC  519.clvleaf_t(base) 528.pot3d_t(base) 535.weather_t(base)

    ------------------------------------------------------------------------------
    GNU Fortran (Spack GCC) 9.3.0
    Copyright (C) 2019 Free Software Foundation, Inc.
    This is free software; see the source for copying conditions.  There is NO
    warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
    ------------------------------------------------------------------------------
    
    ==============================================================================
     CXXC 532.sph_exa_t(base)

    ------------------------------------------------------------------------------
    g++ (Spack GCC) 9.3.0
    Copyright (C) 2019 Free Software Foundation, Inc.
    This is free software; see the source for copying conditions.  There is NO
    warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
    ------------------------------------------------------------------------------
    
    ==============================================================================
     CC  505.lbm_t(base) 513.soma_t(base) 518.tealeaf_t(base) 521.miniswp_t(base)
          534.hpgmgfv_t(base)
    ------------------------------------------------------------------------------
    gcc (Spack GCC) 9.3.0
    Copyright (C) 2019 Free Software Foundation, Inc.
    This is free software; see the source for copying conditions.  There is NO
    warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
    ------------------------------------------------------------------------------

                                             Base Unknown Flags
                                             ------------------
     505.lbm_t: "mpicc" (in CC) "mpicc" (in LD) "-Ofast" (in OPTIMIZE)

    513.soma_t: "mpicc" (in CC) "mpicc" (in LD) "-Ofast" (in OPTIMIZE)

 518.tealeaf_t: "mpicc" (in CC) "mpicc" (in LD) "-Ofast" (in OPTIMIZE)

 519.clvleaf_t: "mpif90" (in FC) "mpif90" (in LD)
                "-fno-stack-arrays" (in FPORTABILITY) "-Ofast" (in OPTIMIZE)

 521.miniswp_t: "mpicc" (in CC) "mpicc" (in LD) "-Ofast" (in OPTIMIZE)

   528.pot3d_t: "mpif90" (in FC) "mpif90" (in LD)
                "-fno-stack-arrays" (in FPORTABILITY) "-Ofast" (in OPTIMIZE)

 532.sph_exa_t: "mpicxx" (in CXX) "mpicxx" (in LD) "-Ofast" (in OPTIMIZE)

 534.hpgmgfv_t: "mpicc" (in CC) "mpicc" (in LD) "-Ofast" (in OPTIMIZE)

 535.weather_t: "mpif90" (in FC) "mpif90" (in LD)
                "-fno-stack-arrays" (in FPORTABILITY) "-Ofast" (in OPTIMIZE)


  SPEChpc is a trademark of the Standard Performance Evaluation
    Corporation.  All other brand and product names appearing in this
    result are trademarks or registered trademarks of their respective
    holders.
############################################################################################################
#   INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN                                #
#                                                                                                          #
# Your run was marked invalid because it has one or more flags in the                                      #
# "unknown" category. You might be able to resolve this problem without                                    #
# re-running your test; see                                                                                #
#      https://www.spec.org/hpc2021/Docs/runhpc.html#flagsurl                                              #
# for more information.                                                                                    #
#                                                                                                          #
#   INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN -- INVALID RUN                                #
############################################################################################################
-------------------------------------------------------------------------------------------------------------
For questions about this result, please contact the tester.
For other inquiries, please contact info@spec.org.
Copyright 2021-2022 Standard Performance Evaluation Corporation
Tested with SPEChpc2021 v1.0.3 on 2022-08-12 16:00:47+0000.
Report generated on 2022-08-12 18:19:36 by hpc2021 ASCII formatter v1.0.3.
